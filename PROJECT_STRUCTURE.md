# Project Structure - Complete Overview

## ğŸ“‚ Current Organization (After Reorganization)

```
options/
â”‚
â”œâ”€â”€ ğŸ“ core/                          # Core business logic
â”‚   â”œâ”€â”€ phase1_clean.py               # Position cleaning (existing)
â”‚   â”œâ”€â”€ phase2_parse.py               # Symbol parsing (existing)
â”‚   â”œâ”€â”€ phase3_enrich/                # Enrichment logic (existing)
â”‚   â”œâ”€â”€ phase6_freeze/                # Freeze logic (existing)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ scan_engine/               # âœ¨ NEW: Modular scan pipeline
â”‚       â”œâ”€â”€ __init__.py               # Package exports & version
â”‚       â”œâ”€â”€ README.md                 # Usage guide & examples
â”‚       â”œâ”€â”€ utils.py                  # Shared validation helpers
â”‚       â”œâ”€â”€ step2_load_snapshot.py    # Load IV/HV CSV (~60 lines)
â”‚       â”œâ”€â”€ step3_filter_ivhv.py      # IVHV gap filtering (~100 lines)
â”‚       â”œâ”€â”€ step5_chart_signals.py    # Chart indicators (~180 lines)
â”‚       â”œâ”€â”€ step6_gem_filter.py       # GEM candidate filtering (~120 lines)
â”‚       â””â”€â”€ pipeline.py               # Full orchestrator (~100 lines)
â”‚
â”œâ”€â”€ ğŸ“ streamlit_app/                 # Dashboard UI
â”‚   â”œâ”€â”€ dashboard.py                  # âœ… Updated: uses scan_engine imports
â”‚   â””â”€â”€ dashboard/                    # Dashboard modules
â”‚       â”œâ”€â”€ chart_engine_runner.py
â”‚       â”œâ”€â”€ pcs_engine_runner.py
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“ utils/                         # Utility helpers
â”œâ”€â”€ ğŸ“ agents/                        # Agent logic
â”œâ”€â”€ ğŸ“ cli/                           # CLI tools
â”œâ”€â”€ ğŸ“ output/                        # Scan outputs (CSVs)
â”‚
â”œâ”€â”€ ğŸ“„ .env.template                  # Environment variable template
â”œâ”€â”€ ğŸ“„ requirements.txt               # Python dependencies
â”œâ”€â”€ ğŸ“„ run_dashboard.sh               # Quick launcher
â”‚
â””â”€â”€ ğŸ“š Documentation/
    â”œâ”€â”€ DASHBOARD_README.md           # How to run dashboard
    â”œâ”€â”€ SCAN_GUIDE.md                 # User guide (2000+ words)
    â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md     # What we built
    â””â”€â”€ REORGANIZATION_SUMMARY.md     # This reorganization
```

---

## ğŸ”„ Data Flow Through Scan Engine

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Input                                â”‚
â”‚  â€¢ Upload CSV or provide file path                           â”‚
â”‚  â€¢ Set min_gap threshold                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: load_ivhv_snapshot.py                               â”‚
â”‚  â€¢ Load Fidelity IV/HV snapshot                              â”‚
â”‚  â€¢ Validate file format                                      â”‚
â”‚  Output: Raw DataFrame (~500-1000 rows)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: filter_ivhv_gap.py                                  â”‚
â”‚  â€¢ Convert IV/HV to numeric                                  â”‚
â”‚  â€¢ Apply liquidity filter (IV>=15, HV>0)                     â”‚
â”‚  â€¢ Calculate IVHV_gap_30D                                    â”‚
â”‚  â€¢ Normalize IV_Rank_XS (0-100)                              â”‚
â”‚  â€¢ Add persona tags (HardPass, SoftPass, PSC_Pass)           â”‚
â”‚  â€¢ Deduplicate by ticker                                     â”‚
â”‚  Output: Filtered tickers (~50-150 rows)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: compute_chart_signals.py                            â”‚
â”‚  â€¢ Fetch 90d history from yfinance                           â”‚
â”‚  â€¢ Calculate EMA9/21, SMA20/50, ATR                          â”‚
â”‚  â€¢ Detect EMA crossovers                                     â”‚
â”‚  â€¢ Calculate trend slope                                     â”‚
â”‚  â€¢ Classify regime (Trending, Ranging, Compressed, etc.)     â”‚
â”‚  Output: Chart-enriched tickers (~40-120 rows)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 6: filter_gem_candidates.py                            â”‚
â”‚  â€¢ Apply directional/neutral validation gates                â”‚
â”‚  â€¢ Filter allowed signal types                               â”‚
â”‚  â€¢ Assign Scan_Tier (Tier 1/2/Trend_Hold)                    â”‚
â”‚  â€¢ Calculate PCS_Seed (68-75)                                â”‚
â”‚  Output: Final GEM candidates (~10-50 rows)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Export & Display                           â”‚
â”‚  â€¢ Save CSV with timestamp                                   â”‚
â”‚  â€¢ Display in dashboard with metrics                         â”‚
â”‚  â€¢ Download button for CSV                                   â”‚
â”‚  â€¢ JSON summary with stats                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Import Patterns

### Pattern 1: Full Pipeline (One-Click)
```python
from core.scan_engine import run_full_scan_pipeline

# Run everything
results = run_full_scan_pipeline(
    snapshot_path='/path/to/snapshot.csv',
    output_dir='./output'
)

# Access results
snapshot = results['snapshot']        # Step 2 output
filtered = results['filtered']        # Step 3 output
charted = results['charted']          # Step 5 output
gem_candidates = results['gem_candidates']  # Step 6 output
```

### Pattern 2: Step-by-Step (Dashboard Style)
```python
from core.scan_engine import (
    load_ivhv_snapshot,
    filter_ivhv_gap,
    compute_chart_signals,
    filter_gem_candidates
)

# Run independently
df_step2 = load_ivhv_snapshot()
df_step3 = filter_ivhv_gap(df_step2, min_gap=2.0)
df_step5 = compute_chart_signals(df_step3)
df_step6 = filter_gem_candidates(df_step5)
```

### Pattern 3: Custom Workflow
```python
from core.scan_engine import (
    load_ivhv_snapshot,
    filter_ivhv_gap,
    classify_regime
)

# Load and filter only
df = load_ivhv_snapshot()
df_filtered = filter_ivhv_gap(df, min_gap=3.5)

# Custom regime analysis
for _, row in df_filtered.iterrows():
    regime = classify_regime({
        'Trend_Slope': row['Trend_Slope'],
        'Atr_Pct': row['Atr_Pct'],
        'Price_vs_SMA20': row['Price_vs_SMA20'],
        'SMA20': row['SMA20']
    })
    print(f"{row['Ticker']}: {regime}")
```

---

## ğŸ§© Module Responsibilities

| Module | Single Responsibility | Imports From | Exported Functions |
|--------|----------------------|--------------|-------------------|
| `utils.py` | Validation helpers | pandas, logging | `validate_input()` |
| `step2_load_snapshot.py` | CSV loading | pandas, os, Path | `load_ivhv_snapshot()` |
| `step3_filter_ivhv.py` | IVHV filtering | pandas, numpy | `filter_ivhv_gap()` |
| `step5_chart_signals.py` | Technical analysis | pandas, yfinance, utils | `compute_chart_signals()`, `classify_regime()` |
| `step6_gem_filter.py` | GEM filtering | pandas, utils | `filter_gem_candidates()` |
| `pipeline.py` | Orchestration | all above steps | `run_full_scan_pipeline()` |
| `__init__.py` | Public API | all modules | All public functions |

---

## ğŸ“ˆ Lines of Code by Responsibility

```
utils.py                 â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  30 lines  (5%)
step2_load_snapshot.py   â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  60 lines  (10%)
step3_filter_ivhv.py     â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘ 100 lines (16%)
step5_chart_signals.py   â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘ 180 lines (30%)
step6_gem_filter.py      â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘ 120 lines (20%)
pipeline.py              â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘ 100 lines (16%)
__init__.py              â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  20 lines  (3%)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total                                 610 lines
```

---

## ğŸ“ Learning Path for New Developers

### Step 1: Understand Individual Steps
1. Read `core/scan_engine/README.md`
2. Review docstrings in each step file
3. Run individual steps in Python console

### Step 2: Trace Data Flow
1. Start with `step2_load_snapshot.py`
2. Follow data transformations through each step
3. Inspect intermediate DataFrames

### Step 3: Test Modifications
1. Pick a step to modify (e.g., `step3_filter_ivhv.py`)
2. Make changes in isolation
3. Test step independently
4. Run full pipeline to verify integration

### Step 4: Extend Pipeline
1. Create `stepX_new_feature.py`
2. Follow docstring template from existing steps
3. Export in `__init__.py`
4. Update `pipeline.py` if needed

---

## ğŸ”§ Maintenance Checklist

### When Fixing Bugs:
- [ ] Identify which step has the issue
- [ ] Open specific step file (not entire pipeline)
- [ ] Fix logic in isolation
- [ ] Test step independently
- [ ] Run full pipeline to verify
- [ ] Update docstring if logic changed

### When Adding Features:
- [ ] Decide if it's a new step or modification
- [ ] Create new file or modify existing
- [ ] Write comprehensive docstring
- [ ] Add to `__init__.py` exports
- [ ] Update `pipeline.py` if orchestration needed
- [ ] Add to dashboard if user-facing

### When Refactoring:
- [ ] Focus on one step at a time
- [ ] Maintain backward compatibility
- [ ] Update docstrings
- [ ] Test before/after behavior matches
- [ ] Update README if usage changes

---

## âœ… Success Metrics

**Code Quality:**
- âœ… Average file size: ~100-150 lines (easy to read)
- âœ… Each file has single responsibility
- âœ… Comprehensive docstrings (200+ lines of docs)
- âœ… Clear import structure

**Maintainability:**
- âœ… Easy to locate specific logic
- âœ… Changes scoped to single file
- âœ… Independent testing possible
- âœ… Multiple devs can work in parallel

**Usability:**
- âœ… Import only what you need
- âœ… Run full pipeline or individual steps
- âœ… Clear error messages with context
- âœ… Dashboard integration seamless

---

## ğŸ‰ Final Status

**Reorganization: COMPLETE** âœ…

All code is now:
- ğŸ“ **Organized** in logical modules
- ğŸ“ **Documented** with comprehensive docstrings
- ğŸ§ª **Testable** independently per step
- ğŸ”„ **Maintainable** with clear separation
- ğŸš€ **Scalable** for future additions

**Next Action:** Start using the new structure!

```bash
# Run the dashboard
streamlit run streamlit_app/dashboard.py

# Or test in Python
python -c "from core.scan_engine import *; print('Ready!')"
```
