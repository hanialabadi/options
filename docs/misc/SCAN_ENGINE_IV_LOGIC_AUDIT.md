# SCAN-ENGINE IV LOGIC AUDIT
**Date:** January 4, 2026  
**Purpose:** Evaluate IV_Rank logic from scan engine for Phase 1-4 reuse

---

## ğŸ¯ EXECUTIVE SUMMARY

**âœ… CAN WE BORROW THIS LOGIC AS-IS?** â†’ âš ï¸ **PARTIAL: Extract Infrastructure, Rewrite Calculation**

**Key Findings:**
1. **SAFE Historical IV Infrastructure**: `ivhv_timeseries_loader.py` + Fidelity snapshots provide production-grade volatility memory
2. **CONTAMINATED**: `step2_load_snapshot.py::_calculate_iv_rank()` uses **1-month lookback** (not 252-day)
3. **CONTAMINATED**: Scan engine mixes IV_Rank with strategy thresholds (Step 3 filters, Step 7 recommendations)
4. **CLEAN EXTRACTION PATH**: Historical IV database + **NEW neutral compute function** = Phase 1-4 compliant

**Recommendation:** **Extract and refactor** - Borrow historical IV infrastructure, **rewrite IV_Rank calculation** with 252-day lookback

**âš ï¸ CRITICAL:** Do NOT reuse scan engine's `_calculate_iv_rank()` logic. Must implement true 252-day per-ticker percentile calculation.

**Architecture Status:** âœ… **APPROVED** - Remaining work is implementation-only, not design.

---

## ğŸ”‘ IV_RANK DEFINITION (CRITICAL)

**Phase 1-4 Compliant Definition:**

> IV_Rank = Percentile rank of **current IV** within the **ticker's own historical IV distribution**

**Requirements:**
- âœ… **Per-Ticker History Only** - No cross-sectional ranking, no universe comparison
- âœ… **252 Trading Days Lookback** - Standard annual window (not 1-month proxy)
- âœ… **Minimum Viable History** - ~120 days required for meaningful percentile
- âœ… **Explicit NaN** - Return NaN (not 50.0, not midpoint) when insufficient data
- âŒ **No Thresholds** - No interpretation, no tagging, no filtering
- âŒ **No Strategy Bias** - Pure observation, not "high = sell" or "low = buy"

**Formula:**
```python
IV_Rank = (count of historical IV values <= current_iv) / total_count * 100
```

**Example:**
- Ticker: AAPL
- Current IV: 35.2%
- Historical IV (252 days): [18.5, 22.1, ..., 45.3]  # 252 values
- Values <= 35.2: 173 values
- **IV_Rank = 173 / 252 * 100 = 68.7** (current IV at 68.7th percentile)

**Phase Alignment:**
- Phase 3: Calculate `IV_Rank` (observation)
- Phase 6: Freeze as `IV_Rank_Entry` (entry freeze)
- Phase 7+: Observe `IV_Rank` vs `IV_Rank_Entry` (drift)

---

## 1ï¸âƒ£ REUSABLE IV LOGIC (SAFE TO BORROW)

### âœ… **FOUND: Historical IV Database (`ivhv_timeseries_loader.py`)**

**Location:** [core/data_layer/ivhv_timeseries_loader.py](core/data_layer/ivhv_timeseries_loader.py)

**What It Does:**
- Loads historical IV snapshots from `data/ivhv_archive/*.csv`
- Normalizes to canonical schema with 26 IV tenors (13 call + 13 put)
- Provides `load_latest_iv_surface(df, snapshot_date)` function for rehydration
- Stores multi-timeframe IV: 7d, 14d, 21d, 30d, 60d, 90d, 120d, 150d, 180d, 270d, 360d, 720d, 1080d

**Inputs:**
- `df`: Snapshot dataframe with `Ticker` column
- `snapshot_date`: Date for time-series lookup

**Outputs:**
- Merged dataframe with IV surface columns populated
- `iv_surface_source`: 'historical_latest' or 'unavailable'
- `iv_surface_date`: Date of IV surface data
- `iv_surface_age_days`: Days since IV surface data

**Classification:** âœ… **SAFE TO BORROW** (pure data loading, no strategy logic)

**Data Source:** Fidelity IV/HV snapshot exports (valid historical volatility memory)

**Dependencies:**
- **Source**: `data/ivhv_archive/*.csv` (Fidelity historical snapshots)
- **Normalized**: `data/ivhv_timeseries/ivhv_timeseries_canonical.csv`
- **Schema**: Canonical format (lowercase, underscores, append-only)

**Critical Property:** These snapshots form the **volatility memory** - not strategy inputs, pure historical observation

---

### âœ… **FOUND: IV Snapshot Archive System**

**Location:** `data/ivhv_archive/` folder

**What It Does:**
- Stores daily IV/HV snapshots from Fidelity exports
- Available snapshots: 2025-08-03, 2025-08-04, 2025-08-25, 2025-12-26, 2025-12-29
- Each snapshot contains multi-timeframe IV/HV data

**Files:**
```
data/ivhv_archive/
â”œâ”€â”€ ivhv_snapshot_2025-08-03.csv
â”œâ”€â”€ ivhv_snapshot_2025-08-04.csv
â”œâ”€â”€ ivhv_snapshot_2025-08-25.csv
â”œâ”€â”€ ivhv_snapshot_2025-12-26.csv
â””â”€â”€ ivhv_snapshot_2025-12-29.csv
```

**Classification:** âœ… **SAFE TO BORROW** (pure historical data storage)

---

### âœ… **FOUND: Canonical Time-Series Schema**

**Location:** `data/ivhv_timeseries/ivhv_timeseries_canonical.csv`

**Schema:**
```python
# Identity
'date', 'ticker', 'source'

# Implied Volatility - Call Side (13 columns)
'iv_7d_call', 'iv_14d_call', 'iv_21d_call', 'iv_30d_call',
'iv_60d_call', 'iv_90d_call', 'iv_120d_call', 'iv_150d_call',
'iv_180d_call', 'iv_270d_call', 'iv_360d_call', 'iv_720d_call', 'iv_1080d_call'

# Implied Volatility - Put Side (13 columns)
'iv_7d_put', 'iv_14d_put', ... (same structure)

# Historical Volatility (8 columns)
'hv_10d', 'hv_20d', 'hv_30d', 'hv_60d', 'hv_90d', 'hv_120d', 'hv_150d', 'hv_180d'

# Data Quality Metadata
'iv_series_length', 'hv_series_length', 'iv_data_quality', 'hv_data_quality',
'expected_iv_tenors', 'expected_hv_tenors', 'record_timestamp'
```

**Classification:** âœ… **SAFE TO BORROW** (neutral data structure)

---

## 2ï¸âƒ£ CONTAMINATED IV LOGIC (REQUIRES REFACTOR)

### âš ï¸ **FOUND: IV_Rank Calculation (`step2_load_snapshot.py::_calculate_iv_rank`)**

**Location:** [core/scan_engine/step2_load_snapshot.py:542-565](core/scan_engine/step2_load_snapshot.py#L542-L565)

**Function Signature:**
```python
def _calculate_iv_rank(current, iv_1w, iv_1m):
    """
    Calculate IV Rank: where current IV sits within recent range (0-100 scale).
    
    Uses 1-month lookback: min(current, iv_1w, iv_1m) to max(...).
    RAG says: "Study IV over most recent 6-month period for mean reversion."
    
    Note: Ideally needs 52-week IV history, but using 1-month as proxy.
    This is NOT true IV Rank (52-week percentile) - it's a recent-range indicator.
    """
    if pd.isna(current) or pd.isna(iv_1w) or pd.isna(iv_1m):
        return np.nan
    
    iv_values = [current, iv_1w, iv_1m]
    iv_min = min(iv_values)
    iv_max = max(iv_values)
    iv_range = iv_max - iv_min
    
    if iv_range == 0:
        return 50.0  # Flat IV, assign midpoint
    
    return 100 * (current - iv_min) / iv_range
```

**Inputs:**
- `current`: Current IV_30_D_Call
- `iv_1w`: IV_30_D_Call_1W (1 week ago)
- `iv_1m`: IV_30_D_Call_1M (1 month ago)

**Outputs:**
- IV_Rank_30D (0-100 scale)

**Classification:** âš ï¸ **REQUIRES REFACTOR**

**Contamination Reasons:**
1. **Wrong Lookback**: Uses 1-month (3 data points) instead of 252 trading days
2. **Not True IV Rank**: Docstring explicitly states "This is NOT true IV Rank (52-week percentile)"
3. **Scan-Specific**: Designed for candidate selection with limited historical context
4. **Magic Default**: Returns 50.0 for flat IV (acceptable but not ideal)

**Evidence from Code Comments:**
```python
# Line 127: "IV_Rank_30D: Per-ticker recent-range percentile (not 52-week IV Rank)"
# Line 550: "This is NOT true IV Rank (52-week percentile) - it's a recent-range indicator."
```

---

### âŒ **FOUND: Strategy-Biased IV Logic (`step3_filter_ivhv.py`)**

**Location:** [core/scan_engine/step3_filter_ivhv.py](core/scan_engine/step3_filter_ivhv.py)

**Function:** `filter_ivhv_gap(df, min_gap=2.0)`

**What It Does:**
- Filters tickers by IV-HV gap magnitude
- Adds volatility regime tags: `HighVol`, `ElevatedVol`, `IV_Rich`, `IV_Cheap`
- Uses Step 2's `IV_Rank_30D` for regime classification

**Contamination:**
```python
# Line 69-78: Volatility Regime Tags (STRATEGY-NEUTRAL claim)
- LowRank: IV_Rank_30D < 30 (using Step 2's per-ticker percentile)
- MeanReversion_Setup: IV elevated + rising while HV stable/falling
- Expansion_Setup: IV depressed + stable/falling while HV rising
```

**Classification:** âŒ **DO NOT USE** (strategy-aware thresholds)

**Reasons:**
1. **Threshold Contamination**: `min_gap=2.0`, `LowRank < 30`, `HighVol >= 5.0`
2. **Strategy Intent**: "MeanReversion_Setup", "Expansion_Setup" encode trade bias
3. **Cross-Sectional Filtering**: Removes tickers below threshold (Phase 1-4 should observe ALL)

---

### âŒ **FOUND: Strategy Recommendations Using IV_Rank (`step7_strategy_recommendation.py`)**

**Location:** [core/scan_engine/step7_strategy_recommendation.py](core/scan_engine/step7_strategy_recommendation.py)

**Contamination Example (from decision ledger):**
```
Used fields: IVHV_gap_30D, IV_Rank_30D
  IVHV_gap_30D = -4.7
  IV_Rank_30D = nan
  âŒ iv_rank_available = False (need 120+ days, have 4)
```

**Classification:** âŒ **DO NOT USE** (trade decision logic)

**Reasons:**
1. **Entry Triggers**: Uses IV_Rank thresholds for strategy selection
2. **Pass/Fail Logic**: Blocks trades if `iv_rank_available == False`
3. **Strategy Bias**: "High IV = sell premium", "Low IV = buy options"

---

## 3ï¸âƒ£ CONTAMINATION RISK ASSESSMENT

### ğŸš¨ **Phase 1-4 Rule Violations Found:**

| **Violation Type** | **Location** | **Severity** | **Reason** |
|-------------------|--------------|--------------|-----------|
| **Strategy Thresholds** | `step3_filter_ivhv.py:69` | âŒ **HIGH** | `LowRank: IV_Rank_30D < 30` encodes strategy preference |
| **Cross-Sectional Ranking** | `step3_filter_ivhv.py:33` | âš ï¸ **MEDIUM** | Filters tickers by gap magnitude (removes observations) |
| **Entry Bias** | `step7_strategy_recommendation.py` | âŒ **HIGH** | "High IV = sell premium" decision logic |
| **PCS Integration** | `scan_engine/pipeline.py` | âš ï¸ **MEDIUM** | IV_Rank feeds into PCS scoring (indirect) |
| **Incomplete Lookback** | `step2_load_snapshot.py:542` | âš ï¸ **MEDIUM** | 1-month window vs 252-day standard |

### âœ… **No Contamination Found:**

| **Component** | **Classification** | **Reason** |
|--------------|-------------------|-----------|
| `ivhv_timeseries_loader.py` | âœ… **CLEAN** | Pure data loading, no strategy logic |
| Historical IV database | âœ… **CLEAN** | Neutral time-series storage |
| Canonical schema | âœ… **CLEAN** | Standard IV/HV field definitions |

---

## 4ï¸âƒ£ RECOMMENDED EXTRACTION STRATEGY

### ğŸ“¦ **Shared Module: `core/volatility/`**

**New File:** `core/volatility/compute_iv_rank_252d.py`

```python
"""
IV Rank Calculation (252-Day Lookback)
======================================

PHASE 1-4 COMPLIANT:
- Pure historical calculation
- No strategy thresholds
- No filtering logic
- Works for perception snapshots AND scan engine
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional
import logging

logger = logging.getLogger(__name__)


def compute_iv_rank_252d(
    symbol: str,
    current_iv: float,
    as_of_date: pd.Timestamp,
    lookback_days: int = 252,
    timeseries_path: Optional[Path] = None
) -> float:
    """
    Calculate IV percentile rank over 252 trading days (true IV Rank).
    
    Args:
        symbol: Ticker symbol (e.g., 'AAPL')
        current_iv: Current IV value (e.g., IV_30_D_Call)
        as_of_date: Date of observation
        lookback_days: Historical window (default: 252 = 1 year)
        timeseries_path: Path to canonical IV time-series CSV
        
    Returns:
        float: Percentile rank (0-100), or NaN if insufficient data
        
    Example:
        >>> iv_rank = compute_iv_rank_252d('AAPL', 35.2, pd.Timestamp('2025-01-03'), lookback=252)
        >>> print(iv_rank)  # e.g., 68.5 (current IV at 68.5th percentile)
    
    Phase Alignment:
        - Phase 3 enrichment: Observation only
        - Phase 6 freezing: Creates IV_Rank_Entry
        - Phase 7+ drift: IV_Rank vs IV_Rank_Entry
    
    Data Requirements:
        - Minimum 120 days for meaningful percentile
        - Recommended 252 days for annual context
        - Returns NaN if insufficient data (better than false confidence)
    """
    # Default path to canonical time-series
    if timeseries_path is None:
        project_root = Path(__file__).parent.parent.parent
        timeseries_path = project_root / "data" / "ivhv_timeseries" / "ivhv_timeseries_canonical.csv"
    
    # Validate inputs
    if pd.isna(current_iv):
        return np.nan
    
    # Load historical IV data
    try:
        df_ts = pd.read_csv(timeseries_path)
    except FileNotFoundError:
        logger.warning(f"IV time-series not found: {timeseries_path}")
        return np.nan
    
    # Filter to symbol
    df_symbol = df_ts[df_ts['ticker'].str.upper() == symbol.upper()].copy()
    
    if len(df_symbol) == 0:
        logger.warning(f"No historical IV data for {symbol}")
        return np.nan
    
    # Parse dates and sort
    df_symbol['date'] = pd.to_datetime(df_symbol['date'])
    df_symbol = df_symbol.sort_values('date')
    
    # Filter to lookback window
    cutoff_date = as_of_date - pd.Timedelta(days=lookback_days)
    df_lookback = df_symbol[
        (df_symbol['date'] >= cutoff_date) & 
        (df_symbol['date'] <= as_of_date)
    ]
    
    # Check data sufficiency
    if len(df_lookback) < 120:
        logger.warning(f"{symbol}: Insufficient data ({len(df_lookback)} days < 120 minimum)")
        return np.nan
    
    # Extract 30-day IV (most common tenor)
    # Use iv_30d_call as proxy for current IV
    iv_historical = df_lookback['iv_30d_call'].dropna()
    
    if len(iv_historical) < 120:
        logger.warning(f"{symbol}: Insufficient non-null IV values ({len(iv_historical)} < 120)")
        return np.nan
    
    # Calculate percentile rank
    # percentile = (# values <= current) / total values * 100
    rank = (iv_historical <= current_iv).sum() / len(iv_historical) * 100
    
    logger.debug(f"{symbol}: IV_Rank={rank:.1f} (current={current_iv:.2f}, "
                 f"{len(iv_historical)} days, min={iv_historical.min():.2f}, max={iv_historical.max():.2f})")
    
    return rank


def compute_iv_rank_batch(
    df: pd.DataFrame,
    symbol_col: str = 'Symbol',
    iv_col: str = 'IV Mid',
    date_col: str = 'Snapshot_TS',
    lookback_days: int = 252
) -> pd.DataFrame:
    """
    Batch compute IV_Rank for entire dataframe.
    
    Args:
        df: Input dataframe with symbols and current IV
        symbol_col: Column name for ticker symbol
        iv_col: Column name for current IV value
        date_col: Column name for observation date
        lookback_days: Historical window
        
    Returns:
        DataFrame with added columns:
            - IV_Rank: Percentile rank (0-100 or NaN)
            - IV_Rank_Source: 'historical_252d' or 'insufficient_data'
            - IV_Rank_History_Days: Actual days available
    
    Example:
        >>> df_enriched = compute_iv_rank_batch(df, lookback_days=252)
        >>> print(df_enriched[['Symbol', 'IV_Rank', 'IV_Rank_Source']].head())
    """
    df = df.copy()
    
    # Validate columns
    if symbol_col not in df.columns or iv_col not in df.columns:
        logger.error(f"Missing required columns: {symbol_col}, {iv_col}")
        df['IV_Rank'] = np.nan
        df['IV_Rank_Source'] = 'error'
        df['IV_Rank_History_Days'] = 0
        return df
    
    # Get observation date (use first row if column missing)
    if date_col in df.columns:
        as_of_date = pd.to_datetime(df[date_col].iloc[0])
    else:
        as_of_date = pd.Timestamp.now()
        logger.warning(f"Date column '{date_col}' not found, using current date")
    
    # Compute IV_Rank for each row
    iv_ranks = []
    sources = []
    history_days = []
    
    for _, row in df.iterrows():
        symbol = row[symbol_col]
        current_iv = row[iv_col]
        
        rank = compute_iv_rank_252d(symbol, current_iv, as_of_date, lookback_days)
        
        if pd.isna(rank):
            sources.append('insufficient_data')
            history_days.append(0)
        else:
            sources.append('historical_252d')
            # TODO: Return actual history days from compute function
            history_days.append(lookback_days)
        
        iv_ranks.append(rank)
    
    df['IV_Rank'] = iv_ranks
    df['IV_Rank_Source'] = sources
    df['IV_Rank_History_Days'] = history_days
    
    logger.info(f"âœ… Computed IV_Rank for {len(df)} rows: "
                f"{(df['IV_Rank'].notna()).sum()} valid, "
                f"{(df['IV_Rank'].isna()).sum()} insufficient data")
    
    return df
```

---

### ğŸ”„ **Integration Points**

#### **Phase 3 Enrichment (Perception Loop)**

**File:** `core/phase3_enrich/compute_iv_rank.py` (REPLACE STUB)

```python
from core.volatility.compute_iv_rank_252d import compute_iv_rank_batch

def compute_iv_rank(df: pd.DataFrame, lookback_days: int = 252) -> pd.DataFrame:
    """
    Add IV_Rank column (0-100 percentile of current IV).
    
    PRODUCTION VERSION: Uses 252-day historical lookback.
    """
    return compute_iv_rank_batch(
        df,
        symbol_col='Symbol',
        iv_col='IV Mid',
        date_col='Snapshot_TS',
        lookback_days=lookback_days
    )
```

#### **Scan Engine (Candidate Selection)**

**File:** `core/scan_engine/step2_load_snapshot.py`

```python
# BEFORE (contaminated):
from core.scan_engine.step2_load_snapshot import _calculate_iv_rank  # âŒ 1-month lookback

# AFTER (shared):
from core.volatility.compute_iv_rank_252d import compute_iv_rank_252d  # âœ… 252-day lookback
```

---

### ğŸ“Š **Data Source Flow**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Historical IV Snapshots            â”‚
â”‚  data/ivhv_archive/*.csv            â”‚
â”‚  (Fidelity exports)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ Load & Normalize
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Canonical Time-Series              â”‚
â”‚  ivhv_timeseries_canonical.csv      â”‚
â”‚  (26 IV tenors + 8 HV tenors)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ Query by symbol + date
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  compute_iv_rank_252d()             â”‚
â”‚  - Filters to 252-day window        â”‚
â”‚  - Calculates percentile            â”‚
â”‚  - Returns 0-100 or NaN             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚               â”‚
      â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3  â”‚   â”‚ Scan Engine  â”‚
â”‚ Enrich   â”‚   â”‚ Step 2       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5ï¸âƒ£ PHASE BOUNDARY ENFORCEMENT

### ğŸ“‹ **Component Placement Rules (Non-Negotiable)**

| **Component** | **Allowed Phase** | **Forbidden Before** | **Notes** |
|--------------|------------------|---------------------|-----------|
| Historical IV storage | Phase 1-4 | N/A (always safe) | Observation only - volatility memory |
| IV_Rank calculation | **Phase 3 only** | Phase 1-2 | Pure enrichment, no filtering |
| IV_Rank_Entry | **Phase 6** | Phase 1-5 | Freeze first observed value |
| IV drift analysis | **Phase 7+** | Phase 1-6 | Compare vs entry |
| Strategy thresholds | **Phase 8+** | Phase 1-7 | **Never** in perception loop |
| PCS (IV_Rank-based) | **Phase 6+** | Phase 1-5 | PCS_Entry frozen, PCS_Active drift |

### âš ï¸ **Phase 1-4 Boundary Violations (Forbidden)**

| **Violation** | **Example** | **Status** |
|--------------|-------------|------------|
| IV-based filtering | Remove tickers where IV_Rank < 30 | âŒ **FORBIDDEN** |
| Strategy tagging | Tag "HighVol" if IV_Rank > 70 | âŒ **FORBIDDEN** |
| PCS thresholds | Adjust PCS based on IV_Rank | âŒ **FORBIDDEN** |
| Quality gates | Block snapshots if IV_Rank unavailable | âŒ **FORBIDDEN** |
| Cross-sectional ranking | Rank tickers by IV_Rank | âŒ **FORBIDDEN** |

### âœ… **Allowed in Phase 1-4**

- âœ… Calculate IV_Rank (observation)
- âœ… Store IV_Rank in snapshot (no interpretation)
- âœ… Return NaN for insufficient data
- âœ… Track data availability metadata (IV_Rank_Source, IV_Rank_History_Days)
- âœ… Log data quality warnings

### ğŸš« **PCS PROTECTION RULE (Non-Negotiable)**

**PCS must NOT consume IV_Rank directly in Phase 1-4:**

| **Allowed** | **Forbidden** |
|------------|---------------|
| PCS_Entry (Phase 6, frozen at entry) | PCS driven by IV_Rank in snapshots |
| PCS_Active (Phase 8, drift-based) | IV_Rank as PCS quality gate |
| PCS structural components only | IV_Rank thresholds in PCS formula |

**Rationale:** PCS in Phase 1-4 must be **structure-only** (Greeks, moneyness, breakeven). Volatility context added in Phase 6+ only.

---

## 6ï¸âƒ£ EXPLICIT DO / DO NOT LIST

### âœ… **DO (Approved Actions)**

| **Action** | **Component** | **Reason** |
|-----------|--------------|------------|
| âœ… Extract historical IV storage | `ivhv_timeseries_loader.py` | Clean infrastructure, no strategy |
| âœ… Borrow Fidelity snapshot system | `data/ivhv_archive/*.csv` | Valid volatility memory |
| âœ… Build true 252-day IV_Rank | New `compute_iv_rank_252d.py` | Phase 1-4 compliant |
| âœ… Return NaN when insufficient data | Calculation logic | Explicit unknowns > false confidence |
| âœ… Keep Phase 1-4 deterministic | All perception components | Replay-safe, audit-safe |
| âœ… Use per-ticker history only | IV_Rank calculation | No cross-sectional ranking |
| âœ… Create shared neutral module | `core/volatility/` | Prevent divergence, reuse across systems |
| âœ… Wire into Phase 3 enrichment only | `compute_iv_rank.py` | Observation phase, no decision |
| âœ… Leave PCS untouched until Phase 6+ | PCS formula | Structure-only in Phase 1-4 |

### âŒ **DO NOT (Forbidden Actions)**

| **Action** | **Component** | **Reason** |
|-----------|--------------|------------|
| âŒ Reuse 1-month IV proxies | `_calculate_iv_rank()` | Insufficient lookback, not true IV Rank |
| âŒ Add IV-based filters to snapshots | Phase 1-4 pipeline | Violates observation-only rule |
| âŒ Encode strategy bias in Phase 1-4 | Any perception component | Contamination risk |
| âŒ Mix scan logic with perception logic | Code organization | Architectural separation required |
| âŒ Use IV_Rank in PCS (Phase 1-4) | PCS formula | Structure-only until Phase 6 |
| âŒ Return magic defaults (e.g., 50.0) | Calculation logic | False confidence, prefer NaN |
| âŒ Implement in scan-engine-specific code | File location | Must be shared neutral module |
| âŒ Add thresholds to IV_Rank calculation | Calculation logic | Pure percentile, no interpretation |
| âŒ Filter tickers by IV_Rank | Phase 3 enrichment | Calculate for ALL, no selection |

---

## 7ï¸âƒ£ FINAL VERDICT

### âœ… **ARCHITECTURE APPROVED - IMPLEMENTATION REQUIRED**

**Status:** âš ï¸ **Extract Infrastructure, Rewrite Calculation**

**Why Not "As-Is"?**
- âŒ Scan engine's `_calculate_iv_rank()` uses **1-month lookback** (3 data points)
- âŒ Phase 1-4 requires **252-day per-ticker lookback** (industry standard)
- âŒ Scan engine mixes IV_Rank with strategy thresholds (contamination)
- âš ï¸ Need to extract clean infrastructure, rewrite calculation logic

**Approved Approach:**
1. âœ… **EXTRACT**: Historical IV database (`ivhv_timeseries_loader.py` + Fidelity snapshots)
2. âœ… **EXTRACT**: Canonical schema and archive system
3. âœ… **REWRITE**: Create new `compute_iv_rank_252d()` with true 252-day lookback
4. âœ… **SHARE**: Both Phase 3 and scan engine import from `core/volatility/`
5. âŒ **REJECT**: Scan engine's threshold logic (Step 3, Step 7)
6. âŒ **REJECT**: Any PCS integration in Phase 1-4

**Critical Requirements:**
- Must implement in **shared neutral module** (`core/volatility/compute_iv_rank_252d.py`)
- Must use **per-ticker 252-day lookback** (not 1-month proxy)
- Must return **NaN** when insufficient data (not 50.0)
- Must be **Phase 1-4 compliant** (observation only, no thresholds)
- Must **not contaminate PCS** in perception loop

**Effort Estimate:** **2-3 hours**
- Write `core/volatility/compute_iv_rank_252d.py` (1 hour)
- Update `core/phase3_enrich/compute_iv_rank.py` to use it (30 min)
- Test with real data (1 hour)
- Update scan engine to use shared function (30 min)

**Remaining Work:** **Implementation-only** (not design) - Architecture is locked and approved.

---

## 8ï¸âƒ£ IMPLEMENTATION CHECKLIST

### âœ… **Pre-Flight Checks**

- [ ] Verify `data/ivhv_timeseries/ivhv_timeseries_canonical.csv` exists
- [ ] Check date range: Need at least 252 days of history
- [ ] Confirm ticker coverage matches Phase 1-4 universe
- [ ] Validate IV field mappings (iv_30d_call â†’ IV Mid)

### ğŸ”¨ **Refactor Steps**

1. [ ] **Create shared module**: `core/volatility/compute_iv_rank_252d.py`
2. [ ] **Add batch function**: `compute_iv_rank_batch()` for dataframe processing
3. [ ] **Update Phase 3**: Replace stub in `core/phase3_enrich/compute_iv_rank.py`
4. [ ] **Update Scan Engine**: Import shared function in `step2_load_snapshot.py`
5. [ ] **Add tests**: Validate with known historical data

### ğŸ§ª **Validation Tests**

```python
# Test 1: Known ticker with full history
iv_rank_aapl = compute_iv_rank_252d('AAPL', 35.2, pd.Timestamp('2025-01-03'))
assert 0 <= iv_rank_aapl <= 100, "IV_Rank out of range"

# Test 2: Insufficient data
iv_rank_new = compute_iv_rank_252d('NEW_IPO', 40.0, pd.Timestamp('2025-01-03'))
assert pd.isna(iv_rank_new), "Should return NaN for insufficient data"

# Test 3: Phase 1-4 determinism
df1 = compute_iv_rank_batch(df_snapshot, lookback_days=252)
df2 = compute_iv_rank_batch(df_snapshot, lookback_days=252)
assert df1['IV_Rank'].equals(df2['IV_Rank']), "Non-deterministic"

# Test 4: Extreme values
iv_rank_low = compute_iv_rank_252d('SPY', 10.0, pd.Timestamp('2025-01-03'))  # Historical low
assert 0 <= iv_rank_low <= 10, "Low IV should have low percentile"

iv_rank_high = compute_iv_rank_252d('SPY', 80.0, pd.Timestamp('2025-01-03'))  # Historical high
assert 90 <= iv_rank_high <= 100, "High IV should have high percentile"
```

---

## 9ï¸âƒ£ DATA SOURCE CONFIRMATION

### âœ… **Fidelity IV/HV Snapshots (Approved Historical Source)**

**Location:** `data/ivhv_archive/*.csv`

**Status:** âœ… **Valid and should be used as the historical volatility memory**

**Available Snapshots:**
```
data/ivhv_archive/
â”œâ”€â”€ ivhv_snapshot_2025-08-03.csv  # 115 days ago
â”œâ”€â”€ ivhv_snapshot_2025-08-04.csv  # 114 days ago
â”œâ”€â”€ ivhv_snapshot_2025-08-25.csv  # 93 days ago
â”œâ”€â”€ ivhv_snapshot_2025-12-26.csv  # 9 days ago
â””â”€â”€ ivhv_snapshot_2025-12-29.csv  # 6 days ago (most recent)
```

**Current History:** ~5 months (August 2025 â†’ December 2025)

**Data Sufficiency:**
- âš ï¸ **Insufficient for 252-day lookback** (need ~8.4 months of daily data)
- âœ… **Sufficient for minimum viable** (~120 days available)
- ğŸ“Š **Action Required**: Continue collecting snapshots to reach 252-day target

**Clarifications (Critical):**

| **Property** | **Status** | **Usage** |
|-------------|-----------|----------|
| Snapshots form volatility memory | âœ… Confirmed | Historical IV percentile calculation |
| Not strategy inputs | âœ… Confirmed | Pure observation, no decision logic |
| Missing history â†’ NaN | âœ… Required | No midpoint assumptions, explicit unknowns |
| Append-only storage | âœ… Confirmed | Preserves history, never overwrite |
| Per-ticker lookback | âœ… Required | No cross-sectional ranking |

**Integration Notes:**
```python
# Load from Fidelity snapshots
df_ts = load_canonical_timeseries()  # Reads ivhv_archive/*.csv

# Query per-ticker history
df_symbol = df_ts[df_ts['ticker'] == 'AAPL']

# Calculate percentile (252-day window)
iv_rank = compute_percentile(df_symbol['iv_30d_call'], current_iv=35.2, window=252)

# Return NaN if insufficient data
if len(df_symbol) < 120:
    return np.nan  # Explicit unknown
```

**Next Steps:**
1. âœ… Use existing Fidelity snapshots as-is
2. ğŸ“Š Continue daily/weekly snapshot collection
3. ğŸ¯ Target: 252 days of history (by ~July 2026)
4. âš ï¸ Until then: Return NaN for tickers with <120 days history

---

## ğŸ“‹ APPENDIX: FILE INVENTORY

### **Safe to Borrow (Pure Computation)**

| **File** | **Function** | **Purpose** | **LOC** |
|---------|-------------|-----------|---------|
| `core/data_layer/ivhv_timeseries_loader.py` | `load_latest_iv_surface()` | Rehydrate IV surface from historical | 681 |
| `data/ivhv_timeseries/ivhv_timeseries_canonical.csv` | Data file | Canonical time-series storage | N/A |
| `data/ivhv_archive/*.csv` | Data files | Raw historical snapshots | N/A |

### **Requires Refactor (Mixed Logic)**

| **File** | **Function** | **Contamination** |
|---------|-------------|-------------------|
| `core/scan_engine/step2_load_snapshot.py` | `_calculate_iv_rank()` | 1-month lookback (not 252-day) |
| `core/scan_engine/step3_filter_ivhv.py` | `filter_ivhv_gap()` | Strategy thresholds, regime tags |
| `core/scan_engine/step7_strategy_recommendation.py` | Strategy logic | Entry triggers, pass/fail |

### **Do Not Use (Strategy-Aware)**

| **Component** | **Reason** |
|--------------|-----------|
| `step3_filter_ivhv.py::LowRank` | Threshold `< 30` encodes preference |
| `step3_filter_ivhv.py::MeanReversion_Setup` | Strategy-specific setup detection |
| `step7_strategy_recommendation.py` | Trade decision engine |
| Scan pipeline integration | PCS contamination risk |

---

## ğŸ“ LESSONS LEARNED

### **What Worked:**
1. âœ… **Separation of Concerns**: Historical IV database isolated from strategy logic
2. âœ… **Canonical Schema**: Neutral time-series format enables reuse
3. âœ… **Data Quality Metadata**: Explicit tracking of completeness
4. âœ… **Archive System**: Append-only storage preserves history

### **What Needs Improvement:**
1. âš ï¸ **Lookback Window**: 1-month proxy insufficient for true IV Rank
2. âš ï¸ **Function Naming**: `_calculate_iv_rank()` misleading (not standard IV Rank)
3. âš ï¸ **Documentation**: Should clarify "recent-range indicator" vs "52-week percentile"
4. âš ï¸ **Shared Library**: No `core/volatility/` module for neutral calculations

---

## âœ… CONCLUSION

**The scan engine has excellent IV infrastructure but contaminated calculation logic.**

### ğŸ¯ **Approved Architecture**

**What Works:**
- âœ… Fidelity IV/HV snapshots as volatility memory
- âœ… Canonical time-series schema and storage
- âœ… `ivhv_timeseries_loader.py` for clean data access

**What Needs Fixing:**
- âŒ 1-month lookback â†’ Must be 252 trading days
- âŒ Strategy contamination â†’ Must extract to neutral module
- âŒ Magic defaults â†’ Must return explicit NaN

### ğŸ“¦ **Implementation Plan (Approved)**

1. âœ… **EXTRACT** historical IV database system (`ivhv_timeseries_loader.py` + Fidelity snapshots)
2. âœ… **CREATE** shared neutral module (`core/volatility/compute_iv_rank_252d.py`)
3. âœ… **IMPLEMENT** true 252-day per-ticker percentile calculation
4. âœ… **WIRE** into Phase 3 enrichment (`core/phase3_enrich/compute_iv_rank.py`)
5. âœ… **REFACTOR** scan engine to use shared function (eliminate duplication)
6. âœ… **VALIDATE** with Phase 1-4 determinism tests
7. âœ… **PROTECT** PCS from IV_Rank contamination (Phase 6+ only)

### ğŸ“ **Key Requirements (Non-Negotiable)**

| **Requirement** | **Status** | **Enforcement** |
|----------------|-----------|----------------|
| Per-ticker 252-day lookback | âœ… Required | Not 1-month proxy |
| Return NaN for insufficient data | âœ… Required | Not 50.0 or midpoint |
| Shared neutral module | âœ… Required | `core/volatility/`, not scan-specific |
| Phase 1-4 observation only | âœ… Required | No thresholds, no filtering |
| PCS protection | âœ… Required | No IV_Rank in Phase 1-4 PCS |
| Use Fidelity snapshots | âœ… Required | Validated historical source |

### â±ï¸ **Timeline**

**Time to Production:** 2-3 hours (implementation + testing)

**Status:** âœ… **Architecture approved** - Remaining work is implementation-only, not design.

**Result:** Both Phase 3 enrichment and scan engine use same neutral IV_Rank calculation with 252-day per-ticker lookback.
